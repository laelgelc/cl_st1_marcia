{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": "# Corpus Linguistics - Study 1 - Phase 1 - Marcia"
  },
  {
   "cell_type": "markdown",
   "id": "886be9c3-175a-47be-99b0-ff77cb1f9bb2",
   "metadata": {},
   "source": [
    "The aim of this phase is to:\n",
    "- Prepare the corpus for tagging with Biber Tagger;\n",
    "- Extract Biber's (1988) Dimension Scores of each text from the Biber Tag Count file."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare the corpus for tagging with Biber Tagger",
   "id": "29e3bc59580ed4d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:32:12.675358Z",
     "start_time": "2025-12-04T20:32:12.109412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define input and output directories\n",
    "input_directory = 'corpus/01_all_seasons_utf_8'\n",
    "output_directory = 'corpus/02_all_seasons_utf_8_fixed'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_path = os.path.join(input_directory, filename)\n",
    "        output_path = os.path.join(output_directory, filename)\n",
    "\n",
    "        try:\n",
    "            with open(input_path, 'r', encoding='utf-8') as f:\n",
    "                # Read all lines to preserve original structure\n",
    "                original_lines = f.readlines()\n",
    "\n",
    "            processed_output = []\n",
    "\n",
    "            for line in original_lines:\n",
    "                # 1. Insert space between digit and letter (e.g., \"1a\" -> \"1 a\")\n",
    "                fixed_line = re.sub(r'(\\d)([a-zA-Z])', r'\\1 \\2', line)\n",
    "\n",
    "                # Strip whitespace to process words, but check if line was just empty space\n",
    "                stripped_line = fixed_line.strip()\n",
    "\n",
    "                if not stripped_line:\n",
    "                    # If the original line was empty (e.g. a paragraph break), preserve it\n",
    "                    processed_output.append(\"\")\n",
    "                    continue\n",
    "\n",
    "                # 2. Wrap every 10 words WITHIN the current line\n",
    "                words = stripped_line.split()\n",
    "\n",
    "                # Chunk the words into groups of 10\n",
    "                for i in range(0, len(words), 10):\n",
    "                    chunk = words[i:i+10]\n",
    "                    processed_output.append(\" \".join(chunk))\n",
    "\n",
    "            # Join all processed lines with newlines\n",
    "            final_output = \"\\n\".join(processed_output)\n",
    "\n",
    "            # Save to the output file\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(final_output)\n",
    "\n",
    "            print(f\"Processed: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"All files processed.\")"
   ],
   "id": "7b5efceb1dc23e64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Amy_Season_10.txt\n",
      "Processed: Amy_Season_11.txt\n",
      "Processed: Amy_Season_12.txt\n",
      "Processed: Amy_Season_3.txt\n",
      "Processed: Amy_Season_4.txt\n",
      "Processed: Amy_Season_5.txt\n",
      "Processed: Amy_Season_6.txt\n",
      "Processed: Amy_Season_7.txt\n",
      "Processed: Amy_Season_8.txt\n",
      "Processed: Amy_Season_9.txt\n",
      "Processed: Bernadette_Season_10.txt\n",
      "Processed: Bernadette_Season_3.txt\n",
      "Processed: Bernadette_Season_4.txt\n",
      "Processed: Bernadette_Season_5.txt\n",
      "Processed: Bernadette_Season_6.txt\n",
      "Processed: Bernadette_Season_7.txt\n",
      "Processed: Bernadette_Season_8.txt\n",
      "Processed: Bernadette_Season_9.txt\n",
      "Processed: Bernardette_Season_11.txt\n",
      "Processed: Bernardette_Season_12.txt\n",
      "Processed: Howard_Season_1.txt\n",
      "Processed: Howard_Season_10.txt\n",
      "Processed: Howard_Season_11.txt\n",
      "Processed: Howard_Season_12.txt\n",
      "Processed: Howard_Season_2.txt\n",
      "Processed: Howard_Season_3.txt\n",
      "Processed: Howard_Season_4.txt\n",
      "Processed: Howard_Season_5.txt\n",
      "Processed: Howard_Season_6.txt\n",
      "Processed: Howard_Season_7.txt\n",
      "Processed: Howard_Season_8.txt\n",
      "Processed: Howard_Season_9.txt\n",
      "Processed: Leonard_Season_1.txt\n",
      "Processed: Leonard_Season_10.txt\n",
      "Processed: Leonard_Season_11.txt\n",
      "Processed: Leonard_Season_12.txt\n",
      "Processed: Leonard_Season_2.txt\n",
      "Processed: Leonard_Season_3.txt\n",
      "Processed: Leonard_Season_4.txt\n",
      "Processed: Leonard_Season_5.txt\n",
      "Processed: Leonard_Season_6.txt\n",
      "Processed: Leonard_Season_7.txt\n",
      "Processed: Leonard_Season_8.txt\n",
      "Processed: Leonard_Season_9.txt\n",
      "Processed: Penny_Season_1.txt\n",
      "Processed: Penny_Season_10.txt\n",
      "Processed: Penny_Season_11.txt\n",
      "Processed: Penny_Season_12.txt\n",
      "Processed: Penny_Season_2.txt\n",
      "Processed: Penny_Season_3.txt\n",
      "Processed: Penny_Season_4.txt\n",
      "Processed: Penny_Season_5.txt\n",
      "Processed: Penny_Season_6.txt\n",
      "Processed: Penny_Season_7.txt\n",
      "Processed: Penny_Season_8.txt\n",
      "Processed: Penny_Season_9.txt\n",
      "Processed: Raj_Season_1.txt\n",
      "Processed: Raj_Season_10.txt\n",
      "Processed: Raj_Season_11.txt\n",
      "Processed: Raj_Season_12.txt\n",
      "Processed: Raj_Season_2.txt\n",
      "Processed: Raj_Season_3.txt\n",
      "Processed: Raj_Season_4.txt\n",
      "Processed: Raj_Season_5.txt\n",
      "Processed: Raj_Season_6.txt\n",
      "Processed: Raj_Season_7.txt\n",
      "Processed: Raj_Season_8.txt\n",
      "Processed: Raj_Season_9.txt\n",
      "Processed: Sheldon_Season_1.txt\n",
      "Processed: Sheldon_Season_10.txt\n",
      "Processed: Sheldon_Season_11.txt\n",
      "Processed: Sheldon_Season_12.txt\n",
      "Processed: Sheldon_Season_2.txt\n",
      "Processed: Sheldon_Season_3.txt\n",
      "Processed: Sheldon_Season_4.txt\n",
      "Processed: Sheldon_Season_5.txt\n",
      "Processed: Sheldon_Season_6.txt\n",
      "Processed: Sheldon_Season_7.txt\n",
      "Processed: Sheldon_Season_8.txt\n",
      "Processed: Sheldon_Season_9.txt\n",
      "Processed: Stuart_Season_10.txt\n",
      "Processed: Stuart_Season_11.txt\n",
      "Processed: Stuart_Season_12.txt\n",
      "Processed: Stuart_Season_2.txt\n",
      "Processed: Stuart_Season_3.txt\n",
      "Processed: Stuart_Season_4.txt\n",
      "Processed: Stuart_Season_5.txt\n",
      "Processed: Stuart_Season_6.txt\n",
      "Processed: Stuart_Season_7.txt\n",
      "Processed: Stuart_Season_8.txt\n",
      "Processed: Stuart_Season_9.txt\n",
      "All files processed.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c5d8918a-11aa-4ba3-b559-c2f6049efd0f",
   "metadata": {},
   "source": "## Extract Biber's (1988) Dimension Scores of each text from the Biber Tag Count file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:34:17.510231Z",
     "start_time": "2025-12-04T20:34:16.834880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_dimensions_from_counts(file_path):\n",
    "    \"\"\"\n",
    "    Captures the filename from the first line and the first 5 values of the 12th line\n",
    "    for each record in the provided counts file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Read lines and strip whitespace, filtering out empty lines to ensure structure\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # The file layout consists of repeating blocks of 12 lines per file\n",
    "    block_size = 12\n",
    "\n",
    "    for i in range(0, len(lines), block_size):\n",
    "        # Check if we have a complete block\n",
    "        if i + 11 >= len(lines):\n",
    "            break\n",
    "\n",
    "        # 1. Capture the filename from the first line of the block\n",
    "        # The line format is: filename value value value\n",
    "        first_line = lines[i]\n",
    "        filename = first_line.split()[0]\n",
    "\n",
    "        # 2. Capture the 5 first values of the 12th line of the block\n",
    "        twelfth_line = lines[i + 11]\n",
    "        values = twelfth_line.split()\n",
    "\n",
    "        # Extract first 5 values and convert to float\n",
    "        dimension_values = [float(v) for v in values[:5]]\n",
    "\n",
    "        # Combine filename and dimensions\n",
    "        row = [filename] + dimension_values\n",
    "        data.append(row)\n",
    "\n",
    "    # Create DataFrame with specified column names\n",
    "    columns = ['Filename', 'Dimension 1', 'Dimension 2', 'Dimension 3', 'Dimension 4', 'Dimension 5']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "# df = extract_dimensions_from_counts('counts.txt')\n",
    "# print(df.head())"
   ],
   "id": "7c107fe266cc25d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "619848b5-ef5e-4b89-8ff5-45a8f7d4a6c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:34:34.654919Z",
     "start_time": "2025-12-04T20:34:34.646654Z"
    }
   },
   "source": [
    "# Define the path to the Biber Tag Count file\n",
    "counts_all_seasons_utf_8 = 'corpus/03_all_seasons_utf_8_tagged/tagcount/counts.txt'\n",
    "\n",
    "# Extract dimensions from counts\n",
    "df_dimensions_all_seasons_utf_8 = extract_dimensions_from_counts(counts_all_seasons_utf_8)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:34:37.144335Z",
     "start_time": "2025-12-04T20:34:37.128016Z"
    }
   },
   "cell_type": "code",
   "source": "df_dimensions_all_seasons_utf_8",
   "id": "ffbe5d08600592cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Filename  Dimension 1  Dimension 2  Dimension 3  Dimension 4  \\\n",
       "0     amy_season_10.txt        34.71        -2.08        -3.24        -1.21   \n",
       "1     amy_season_11.txt        47.85        -1.30        -3.99         2.55   \n",
       "2     amy_season_12.txt        51.11        -1.60        -3.23         1.87   \n",
       "3      amy_season_3.txt         9.50        -1.31        -7.90         9.31   \n",
       "4      amy_season_4.txt        13.98        -2.65        -0.57         0.17   \n",
       "..                  ...          ...          ...          ...          ...   \n",
       "86  stuart_season_5.txt        18.89        -3.24        -0.49        -2.76   \n",
       "87  stuart_season_6.txt        35.28        -3.74        -6.12        -1.18   \n",
       "88  stuart_season_7.txt        29.91        -2.23        -4.12        -2.91   \n",
       "89  stuart_season_8.txt        33.94        -0.30        -5.07        -2.35   \n",
       "90  stuart_season_9.txt        28.89        -1.39        -3.20        -1.31   \n",
       "\n",
       "    Dimension 5  \n",
       "0          6.22  \n",
       "1          7.92  \n",
       "2          5.86  \n",
       "3         -3.63  \n",
       "4          2.83  \n",
       "..          ...  \n",
       "86         3.61  \n",
       "87         0.89  \n",
       "88         4.72  \n",
       "89         5.61  \n",
       "90         6.55  \n",
       "\n",
       "[91 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Dimension 1</th>\n",
       "      <th>Dimension 2</th>\n",
       "      <th>Dimension 3</th>\n",
       "      <th>Dimension 4</th>\n",
       "      <th>Dimension 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amy_season_10.txt</td>\n",
       "      <td>34.71</td>\n",
       "      <td>-2.08</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>6.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amy_season_11.txt</td>\n",
       "      <td>47.85</td>\n",
       "      <td>-1.30</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>2.55</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amy_season_12.txt</td>\n",
       "      <td>51.11</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>1.87</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amy_season_3.txt</td>\n",
       "      <td>9.50</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-7.90</td>\n",
       "      <td>9.31</td>\n",
       "      <td>-3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amy_season_4.txt</td>\n",
       "      <td>13.98</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>stuart_season_5.txt</td>\n",
       "      <td>18.89</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-2.76</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>stuart_season_6.txt</td>\n",
       "      <td>35.28</td>\n",
       "      <td>-3.74</td>\n",
       "      <td>-6.12</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>stuart_season_7.txt</td>\n",
       "      <td>29.91</td>\n",
       "      <td>-2.23</td>\n",
       "      <td>-4.12</td>\n",
       "      <td>-2.91</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>stuart_season_8.txt</td>\n",
       "      <td>33.94</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-5.07</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>5.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>stuart_season_9.txt</td>\n",
       "      <td>28.89</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-3.20</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "df59d7f7-4d86-4973-a999-a22474b39a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:34:41.613521Z",
     "start_time": "2025-12-04T20:34:41.608666Z"
    }
   },
   "source": "df_dimensions_all_seasons_utf_8.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "0d348f64-e4db-48b2-a434-1cb27d9a4419",
   "metadata": {},
   "source": "## Exporting to a file"
  },
  {
   "cell_type": "code",
   "id": "f49c17cd-bd32-4c2f-86bd-98028b8e42fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:36:43.157104Z",
     "start_time": "2025-12-04T20:36:43.126120Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define output directory\n",
    "output_directory = 'cl_st1_ph1_marcia'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Define output filename\n",
    "filename = 'dimensions_all_seasons_utf_8'\n",
    "\n",
    "# Export to JSONL\n",
    "df_dimensions_all_seasons_utf_8.to_json(f\"{output_directory}/{filename}.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# Export to Excel\n",
    "df_dimensions_all_seasons_utf_8.to_excel(f\"{output_directory}/{filename}.xlsx\", index=False)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8dddd4ee-e3ff-4a59-8abc-284e9e939096",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
